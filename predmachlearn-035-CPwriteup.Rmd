---
title: "Practical Machine Learning - Course Project:Writeup"
author: "Oliver Loper"
date: "December 25, 2015"
output: html_document
---

## Intro
The submission is a course project writeup part for the JHU Coursera Practical Machine Learning course. The approach chosen is to clean the given dataset and apply 3 different techniques on it and choose the one performs the best on training dataset.

## Preparations
### Cleaning Data
Filtering out fields that do not add value from machine learning point of view. Such columns are selected as following:
* No useful info: index, timestamps, time window related
* Majority of data missing:  possible preprocessing columns that should contain variance, average, minimum, maximum, skewness, kurtosis, standard deviations of parameters but is rarely filled in. Although the column names are interpretable the criteria chosen is to filter out columns lacking at least 95% of numeric values.

```{r, message=FALSE}
rawdata<-read.csv("pml-training.csv")
library(dplyr)
data<-select(rawdata, c(-1, -3:-7,-12:-36, -50:-59, -69:-83, -87:-101, -103:-112, -125:-139, -141:-150))

```

This results in reducing the variables from 160 to 54.
The main benefit of cleaning the data is in speed of processing â€“ factor variables are most problematic in that sense. Only one factor variable remained in and that is the user_name. But also to avoid dependency between index and classe as the table is sorted by classe before indexing.

### Splitting the training data into training and test sets
```{r, cache=TRUE, message=FALSE}
set.seed(111222)
library(caret)
inTrain <- createDataPartition(y=data$classe, p=0.7, list=FALSE)
training<-data[inTrain,]
testing<-data[-inTrain,]
```

## Trying out methods
Intuition says that for such predicting tasks the trees might be sufficient, but it feels a bit suspicious that this area gets so much attention if it was a satisfying solution.
### Simple trees
```{r, message=FALSE}
modFit<-train(training$classe~., method="rpart", data=training, tuneLength=20)
RPtest <-predict(modFit, testing[,-54])
confusionMatrix(testing$classe, RPtest)
```
The method is very fast, but the accuracy is not satisfying. It was also tried out with pre-processing using pca, but it did not give significant improvement. The length tuning gives some benefit, but increasing the length gets close to overfitting.

### Boosting with trees
```{r, cache=TRUE, message=FALSE}
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
modFit2<-train(training$classe~., method="gbm", data=training, trControl=fitControl, verbose=FALSE)
RPtest <-predict(modFit2, testing[,-54])
confusionMatrix(testing$classe, RPtest)
```
The solution is suffieciently accurate. 

### Random forest
```{r, cache=TRUE, message=FALSE}
modFitRF<-train(training$classe~., method="rf", data=training)
RPtest <-predict(modFitRF, testing[,-54])
confusionMatrix(testing$classe, RPtest)
```
This solution is quite precise, but takes rather long to compute.

## Summary
### Conclusions
The random forest gave the best precision, but boosting with trees was remarkably faster. Possibly boosting with trees could have been tuned better with selecting better folds and repetitions so it would achieved better accuracy and remained faster.
### Exporting the results
This part is an example with boosting using trees.
```{r, message=FALSE}
pml_write_files = function(x){
    n = length(x)
    for(i in 1:n){
        filename = paste0("problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}
rawtestdata<-read.csv("pml-testing.csv")
testdata<-select(rawtestdata, c(-1, -3:-7,-12:-36, -50:-59, -69:-83, -87:-101, -103:-112, -125:-139, -141:-150))
RPtest <-predict(modFit2, testdata[,-54])
pml_write_files(RPtest)
```
More complex approaches scored 20/20 with the initially given test set.
